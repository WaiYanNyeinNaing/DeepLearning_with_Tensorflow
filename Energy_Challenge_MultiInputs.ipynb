{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # for nicer plots\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import re\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "#Pre-processing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Measuring Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(123)         # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>appliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1980</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>1981</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>1983</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1985</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1986</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1987</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  appliance\n",
       "980  1980          5\n",
       "981  1981          7\n",
       "982  1982          1\n",
       "983  1983          5\n",
       "984  1984          1\n",
       "985  1985          6\n",
       "986  1986          9\n",
       "987  1987         10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the dataset\n",
    "\n",
    "raw = pd.read_csv('train_labels.csv')\n",
    "raw[980:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  7,  1,  5,  1,  6,  9, 10], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label1 = np.array(raw)\n",
    "label = label1[:,1]\n",
    "label[980:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/train/train_voltage\\\\1980_v.png',\n",
       " 'data/train/train_voltage\\\\1981_v.png',\n",
       " 'data/train/train_voltage\\\\1982_v.png',\n",
       " 'data/train/train_voltage\\\\1983_v.png',\n",
       " 'data/train/train_voltage\\\\1984_v.png',\n",
       " 'data/train/train_voltage\\\\1985_v.png',\n",
       " 'data/train/train_voltage\\\\1986_v.png',\n",
       " 'data/train/train_voltage\\\\1987_v.png']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import glob\n",
    "import pylab as plt\n",
    "\n",
    "\n",
    "#Input 1 (Train_voltage)\n",
    "\n",
    "folders_voltage = glob.glob('data/train/train_voltage/*.png')\n",
    "\n",
    "imagenames_list = []\n",
    "train_voltage = []\n",
    "\n",
    "\n",
    "for folder in folders_voltage:\n",
    "    for f in glob.glob(folder):\n",
    "        imagenames_list.append(f)\n",
    "\n",
    "read_images = []        \n",
    "\n",
    "for image1 in imagenames_list:\n",
    "    image = cv2.imread(image1)\n",
    "    image = cv2.resize(image, (128, 118))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #image = img_to_array(image)\n",
    "    train_voltage.append(gray)\n",
    "    \n",
    "\n",
    "train_voltage = np.array(train_voltage)\n",
    "train_voltage = train_voltage.reshape(train_voltage.shape[0], 128, 118, 1)\n",
    "train_voltage.shape\n",
    "imagenames_list[980:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/train/train_current\\\\1980_c.png',\n",
       " 'data/train/train_current\\\\1981_c.png',\n",
       " 'data/train/train_current\\\\1982_c.png',\n",
       " 'data/train/train_current\\\\1983_c.png',\n",
       " 'data/train/train_current\\\\1984_c.png',\n",
       " 'data/train/train_current\\\\1985_c.png',\n",
       " 'data/train/train_current\\\\1986_c.png',\n",
       " 'data/train/train_current\\\\1987_c.png']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input 2 (Train_current)\n",
    "\n",
    "folders_current = glob.glob('data/train/train_current/*.png')\n",
    "\n",
    "imagenames_list2 = []\n",
    "train_current = []\n",
    "\n",
    "\n",
    "for folder in folders_current:\n",
    "    for f in glob.glob(folder):\n",
    "        imagenames_list2.append(f)\n",
    "\n",
    "read_images = []        \n",
    "\n",
    "for image1 in imagenames_list2:\n",
    "    image = cv2.imread(image1)\n",
    "    image = cv2.resize(image, (128, 118))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #image = img_to_array(image)\n",
    "    train_current.append(gray)\n",
    "    \n",
    "\n",
    "train_current = np.array(train_current)\n",
    "train_current = train_current.reshape(train_current.shape[0], 128, 118, 1)\n",
    "train_current.shape\n",
    "imagenames_list2[980:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Convert dataset into train and test part (20% data as test set)\n",
    "split = train_test_split(train_voltage, train_current, label,test_size=0.2,shuffle=False)\n",
    "\n",
    "(Tr_voltage, Te_voltage, Tr_current, Te_current, Tr_label, Te_label) = split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train voltage:  (790, 128, 118, 1)\n",
      "train current:  (790, 128, 118, 1)\n",
      "first 10 labels:  [ 8  1  8 10  6  1 10  2  0  5]\n",
      "train label:  (790, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"train voltage: \" , Tr_voltage.shape)\n",
    "print(\"train current: \" , Tr_current.shape)\n",
    "print(\"first 10 labels: \" , Tr_label[:10])\n",
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "# One-hot encode the labels\n",
    "Tr_label = tf.keras.utils.to_categorical(Tr_label, 11)\n",
    "print(\"train label: \" , Tr_label.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test voltage:  (198, 128, 118, 1)\n",
      "test current:  (198, 128, 118, 1)\n",
      "second last 10 labels:  [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "test label:  (198, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"test voltage: \" , Te_voltage.shape)\n",
    "print(\"test current: \" , Te_current.shape)\n",
    "print(\"second last 10 labels: \" , Tr_label[:10])\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# One-hot encode the labels\n",
    "Te_label = tf.keras.utils.to_categorical(Te_label, 11)\n",
    "print(\"test label: \" , Te_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test label:  (988, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# One-hot encode the labels\n",
    "label = tf.keras.utils.to_categorical(label, 11)\n",
    "print(\"test label: \" , label.shape)\n",
    "\n",
    "label[980:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Inputs\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "#Model\n",
    "# first input model\n",
    "voltage = Input(shape=(128,118,1))\n",
    "conv11 = Conv2D(32, kernel_size=4, activation='relu')(voltage)\n",
    "pool11 = MaxPooling2D(pool_size=(2, 2))(conv11)\n",
    "conv12 = Conv2D(16, kernel_size=4, activation='relu')(pool11)\n",
    "pool12 = MaxPooling2D(pool_size=(2, 2))(conv12)\n",
    "conv13 = Conv2D(8, kernel_size=4, activation='relu')(pool12)\n",
    "pool13 = MaxPooling2D(pool_size=(2, 2))(conv13)\n",
    "flat1 = Flatten()(pool13)\n",
    "\n",
    "# second input model\n",
    "current = Input(shape=(128,118,1))\n",
    "conv21 = Conv2D(32, kernel_size=4, activation='relu')(current)\n",
    "pool21 = MaxPooling2D(pool_size=(2, 2))(conv21)\n",
    "conv22 = Conv2D(16, kernel_size=4, activation='relu')(pool21)\n",
    "pool22 = MaxPooling2D(pool_size=(2, 2))(conv22)\n",
    "conv23 = Conv2D(8, kernel_size=4, activation='relu')(pool22)\n",
    "pool23 = MaxPooling2D(pool_size=(2, 2))(conv23)\n",
    "flat2 = Flatten()(pool23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 128, 118, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 128, 118, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 125, 115, 32) 544         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 125, 115, 32) 544         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 62, 57, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 62, 57, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 59, 54, 16)   8208        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 59, 54, 16)   8208        max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 29, 27, 16)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 29, 27, 16)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 26, 24, 8)    2056        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 26, 24, 8)    2056        max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 13, 12, 8)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 13, 12, 8)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1248)         0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1248)         0           max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2496)         0           flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          1278464     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          131328      dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 11)           2827        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,434,235\n",
      "Trainable params: 1,434,235\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# merge input models\n",
    "merge = concatenate([flat1, flat2])\n",
    "# interpretation model\n",
    "hidden1 = Dense(512, activation='relu')(merge)\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "hidden3 = Dropout(0.5)(hidden2)\n",
    "output = Dense(11, activation='softmax')(hidden3)\n",
    "model = Model(inputs=[voltage, current], outputs=output)\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "\n",
    "# plot graph\n",
    "#plot_model(model, to_file='multiple_inputs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.nadam()\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'Adam' , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])# Set a learning rate annealer\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 64\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 0, mode= 'min')\n",
    "model_filepath='.weights.best.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [early_stopping, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 40)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=666)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=666)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "gen_flow = gen_flow_for_two_inputs(Tr_voltage, Tr_current, Tr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/12 [===============================] - 2s 146ms/step - loss: 0.0377 - acc: 0.9875 - val_loss: 0.1030 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10296, saving model to .weights.best.hdf5\n",
      "Epoch 2/100\n",
      "13/12 [===============================] - 2s 127ms/step - loss: 0.0308 - acc: 0.9894 - val_loss: 0.0879 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10296 to 0.08791, saving model to .weights.best.hdf5\n",
      "Epoch 3/100\n",
      "13/12 [===============================] - 2s 123ms/step - loss: 0.0229 - acc: 0.9918 - val_loss: 0.0999 - val_acc: 0.9660\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.08791\n",
      "Epoch 4/100\n",
      "13/12 [===============================] - 2s 127ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.1032 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08791\n",
      "Epoch 5/100\n",
      "13/12 [===============================] - 2s 129ms/step - loss: 0.0211 - acc: 0.9925 - val_loss: 0.1100 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08791\n",
      "Epoch 6/100\n",
      "13/12 [===============================] - 2s 129ms/step - loss: 0.0149 - acc: 0.9957 - val_loss: 0.0943 - val_acc: 0.9692\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08791\n",
      "Epoch 7/100\n",
      "13/12 [===============================] - 2s 127ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0931 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19a32c5f208>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using our generator defined above\n",
    "model.fit_generator(gen_flow, validation_data=([Te_voltage, Te_current],Te_label),steps_per_epoch= len(Tr_voltage) / batch_size,\n",
    "                    epochs=100,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H = model.fit([train_voltage,train_current], label,\n",
    "#              epochs=epochs,verbose=1,validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659, 128, 118, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/test/test_voltage\\\\1988_v.png',\n",
       " 'data/test/test_voltage\\\\1989_v.png',\n",
       " 'data/test/test_voltage\\\\1990_v.png',\n",
       " 'data/test/test_voltage\\\\1991_v.png',\n",
       " 'data/test/test_voltage\\\\1992_v.png',\n",
       " 'data/test/test_voltage\\\\1993_v.png',\n",
       " 'data/test/test_voltage\\\\1994_v.png',\n",
       " 'data/test/test_voltage\\\\1995_v.png',\n",
       " 'data/test/test_voltage\\\\1996_v.png',\n",
       " 'data/test/test_voltage\\\\1997_v.png']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input 1 (Test_voltage)\n",
    "\n",
    "folders_voltage_test = glob.glob('data/test/test_voltage/*.png')\n",
    "\n",
    "imagenames_list_test = []\n",
    "test_voltage = []\n",
    "\n",
    "\n",
    "for folder in folders_voltage_test:\n",
    "    for f in glob.glob(folder):\n",
    "        imagenames_list_test.append(f)\n",
    "\n",
    "read_images = []        \n",
    "\n",
    "for image1 in imagenames_list_test:\n",
    "    image = cv2.imread(image1)\n",
    "    image = cv2.resize(image, (128, 118))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #image = img_to_array(image)\n",
    "    test_voltage.append(gray)\n",
    "    \n",
    "\n",
    "test_voltage = np.array(test_voltage)\n",
    "test_voltage = test_voltage.reshape(test_voltage.shape[0], 128, 118, 1)\n",
    "print(test_voltage.shape)\n",
    "imagenames_list_test[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(659, 128, 118, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['data/test/test_current\\\\1988_c.png',\n",
       " 'data/test/test_current\\\\1989_c.png',\n",
       " 'data/test/test_current\\\\1990_c.png',\n",
       " 'data/test/test_current\\\\1991_c.png',\n",
       " 'data/test/test_current\\\\1992_c.png',\n",
       " 'data/test/test_current\\\\1993_c.png',\n",
       " 'data/test/test_current\\\\1994_c.png',\n",
       " 'data/test/test_current\\\\1995_c.png',\n",
       " 'data/test/test_current\\\\1996_c.png',\n",
       " 'data/test/test_current\\\\1997_c.png']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input 2 (Test_current)\n",
    "\n",
    "folders_voltage_testc = glob.glob('data/test/test_current/*.png')\n",
    "\n",
    "imagenames_list_testc = []\n",
    "test_current = []\n",
    "\n",
    "\n",
    "for folder in folders_voltage_testc:\n",
    "    for f in glob.glob(folder):\n",
    "        imagenames_list_testc.append(f)\n",
    "\n",
    "read_images = []        \n",
    "\n",
    "for image1 in imagenames_list_testc:\n",
    "    image = cv2.imread(image1)\n",
    "    image = cv2.resize(image, (128, 118))\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #image = img_to_array(image)\n",
    "    test_current.append(gray)\n",
    "    \n",
    "\n",
    "test_current = np.array(test_current)\n",
    "test_current = test_current.reshape(test_current.shape[0], 128, 118, 1)\n",
    "print(test_current.shape)\n",
    "imagenames_list_testc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 2, 8, 2, 5, 8, 3, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict results\n",
    "results = model.predict([test_voltage,test_current])\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(results,name=\"appliance\")\n",
    "\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"submission_format.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
